{
  "name": "Contextual Retrieval + Reranking RAG Workshop",
  "nodes": [
    {
      "parameters": {
        "model": "gpt-4.1-mini",
        "options": {}
      },
      "id": "1e2d5c67-366d-4f8f-9ab9-c4d28c05fb36",
      "name": "OpenAI Chat Model",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1,
      "position": [
        300,
        300
      ],
      "credentials": {
        "openAiApi": {
          "id": "cL3Rz97TY4TerdNi",
          "name": "OpenAi account 3"
        }
      }
    },
    {
      "parameters": {
        "jsonMode": "expressionData",
        "jsonData": "={{\n{\n  \"content\": `${ $json.text }\\n---\\n${ $json.chunk }`\n}\n}}",
        "options": {
          "metadata": {
            "metadataValues": [
              {
                "name": "=file_id",
                "value": "={{ $('Set File ID').first().json.file_id }}"
              },
              {
                "name": "file_title",
                "value": "={{ $('Set File ID').first().json.file_title }}"
              }
            ]
          }
        }
      },
      "id": "ec7161be-79da-4df9-9310-ce7cf0ce668d",
      "name": "Default Data Loader",
      "type": "@n8n/n8n-nodes-langchain.documentDefaultDataLoader",
      "typeVersion": 1,
      "position": [
        2440,
        1020
      ]
    },
    {
      "parameters": {
        "model": "text-embedding-3-small",
        "options": {}
      },
      "id": "0d88545a-05cc-4268-998c-0f3c56aa0480",
      "name": "Embeddings OpenAI1",
      "type": "@n8n/n8n-nodes-langchain.embeddingsOpenAi",
      "typeVersion": 1,
      "position": [
        2280,
        1020
      ],
      "credentials": {
        "openAiApi": {
          "id": "cL3Rz97TY4TerdNi",
          "name": "OpenAi account 3"
        }
      }
    },
    {
      "parameters": {
        "content": "## Tool to Add Google Drive Files to Vector DB with Contextual Embeddings",
        "height": 867,
        "width": 2853,
        "color": 5
      },
      "id": "60f8945c-deef-4478-b458-ea1a7938bf51",
      "name": "Sticky Note1",
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        0,
        500
      ]
    },
    {
      "parameters": {
        "operation": "text",
        "options": {}
      },
      "id": "9335f928-f645-4d49-baf4-340224a64d44",
      "name": "Extract Document Text",
      "type": "n8n-nodes-base.extractFromFile",
      "typeVersion": 1,
      "position": [
        1100,
        620
      ],
      "alwaysOutputData": true
    },
    {
      "parameters": {
        "sessionIdType": "customKey",
        "sessionKey": "={{ $(\"When chat message received\").item.json.sessionId }}"
      },
      "id": "dbf65348-63f2-4547-a6d7-d055a5528674",
      "name": "Postgres Chat Memory",
      "type": "@n8n/n8n-nodes-langchain.memoryPostgresChat",
      "typeVersion": 1,
      "position": [
        480,
        300
      ],
      "notesInFlow": false,
      "credentials": {
        "postgres": {
          "id": "UaTmh0frrACTMPxG",
          "name": "Postgres account"
        }
      }
    },
    {
      "parameters": {
        "content": "## RAG AI Agent with Contextual Retrieval + Reranking",
        "height": 485,
        "width": 856
      },
      "id": "aeb910f4-007e-4f5a-aa56-aab3ac21e7f9",
      "name": "Sticky Note2",
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        0,
        0
      ]
    },
    {
      "parameters": {
        "options": {
          "systemMessage": "=## Role\n\nYou are a Retrieval-Augmented Generation (RAG) assistant designed to answer questions a user has. You use a corpus of documents that are all text based. Your primary goal is to provide accurate, up-to-date, and relevant information based on what the user asks and the documents you retrieve.\n\n## Responsibilities\n\n- Answer user queries with a good mix of being comprehensive but still concise\n- Present information in an easy-to-understand and professional manner  \n- Clarify misconceptions or misinformation\n\n## Other Key Information and Instructions\n\n- Always tell the user if you didn't find the answer. Don't make something up just to please them.\n- Keep your language neutral and factual. Do not show bias or opinion  \n\n## Error Handling\n- If the information cannot be found using the provided instructions respond with:  \n  “I’m sorry, I couldn’t find relevant information based on your documents.”\n"
        }
      },
      "id": "6c53c783-31b7-426e-95fb-4b8b64027812",
      "name": "RAG AI Agent",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 1.6,
      "position": [
        380,
        80
      ]
    },
    {
      "parameters": {
        "options": {
          "reset": false
        }
      },
      "type": "n8n-nodes-base.splitInBatches",
      "typeVersion": 3,
      "position": [
        280,
        620
      ],
      "id": "a5fb91f5-ff8f-4790-81c8-4f0a6a160249",
      "name": "Loop Over Items"
    },
    {
      "parameters": {
        "chunkSize": 2000,
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.textSplitterRecursiveCharacterTextSplitter",
      "typeVersion": 1,
      "position": [
        2560,
        1180
      ],
      "id": "503b8dd8-6eb6-4968-9428-3515df741446",
      "name": "Recursive Character Text Splitter"
    },
    {
      "parameters": {
        "public": true,
        "options": {}
      },
      "id": "70b176bc-f95e-4d88-a65f-eeb9ec32fe4e",
      "name": "When chat message received",
      "type": "@n8n/n8n-nodes-langchain.chatTrigger",
      "typeVersion": 1.1,
      "position": [
        100,
        80
      ],
      "webhookId": "2e7c037a-cf2e-40c5-9bed-e0944cc03cfa"
    },
    {
      "parameters": {
        "mode": "runOnceForEachItem",
        "jsCode": "const chunks = [];\nconst chunkSize = 400;\nconst chunkOverlap = 0;\nconst text = $json.data.replace(/\\n/, '');\n\nfor (let i=0, j=Math.round(text.length/chunkSize); i<j; i++) {\n  chunks.push(\n    text.substr(\n      Math.max(0,(i * chunkSize)-chunkOverlap),\n      chunkSize\n    )\n  );\n}\n\nreturn { chunks };"
      },
      "id": "2a0c8b38-1a51-4185-8e8c-341decdbd644",
      "name": "Create Chunks From Doc",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1340,
        780
      ]
    },
    {
      "parameters": {
        "fieldToSplitOut": "chunks",
        "options": {
          "destinationFieldName": "chunk"
        }
      },
      "id": "5c6e585d-c289-4ef0-85d7-89ae1cadf97c",
      "name": "Chunks To List",
      "type": "n8n-nodes-base.splitOut",
      "typeVersion": 1,
      "position": [
        1560,
        640
      ]
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=<document> \n{{ $('Extract Document Text').first().json.data }} \n</document>\nHere is the chunk we want to situate within the whole document \n<chunk> \n{{ $json.chunk }}\n</chunk> \nPlease give a short succinct context to situate this chunk within the overall document for the purposes of improving search retrieval of the chunk. Answer only with the succinct context and nothing else. "
      },
      "id": "618695a7-9ac5-4d53-972e-c4fe83f7ee9b",
      "name": "Generate Contextual Text",
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "typeVersion": 1.4,
      "position": [
        1780,
        780
      ]
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "gpt-4.1-nano",
          "mode": "list",
          "cachedResultName": "gpt-4.1-nano"
        },
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        1740,
        1020
      ],
      "id": "df798fed-2d17-409d-8f00-d9b23358747d",
      "name": "OpenAI Chat Model3",
      "credentials": {
        "openAiApi": {
          "id": "cL3Rz97TY4TerdNi",
          "name": "OpenAi account 3"
        }
      }
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "069d067c-3534-4939-8ff4-34dee02a9436",
              "name": "chunk",
              "value": "={{ $('Chunks To List').item.json.chunk }}",
              "type": "string"
            },
            {
              "id": "24e01f4f-e156-47e9-a89e-9cbdccda6bd4",
              "name": "text",
              "value": "={{ $('Generate Contextual Text').item.json.text }}",
              "type": "string"
            }
          ]
        },
        "options": {}
      },
      "id": "22da3713-54f7-4e8b-91b6-8ac09ef35a1d",
      "name": "Get Values",
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        2140,
        660
      ]
    },
    {
      "parameters": {
        "mode": "insert",
        "tableName": "documents_reranking",
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.vectorStorePGVector",
      "typeVersion": 1.1,
      "position": [
        2360,
        760
      ],
      "id": "448b2e44-3dfe-4ef5-9639-96c451072de4",
      "name": "Postgres PGVector Store",
      "credentials": {
        "postgres": {
          "id": "UaTmh0frrACTMPxG",
          "name": "Postgres account"
        }
      }
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "DO $$\nBEGIN\n    IF EXISTS (SELECT 1 FROM information_schema.tables WHERE table_name = 'documents_reranking') THEN\n        EXECUTE 'DELETE FROM documents_reranking WHERE metadata->>''file_id'' LIKE ''%' || $1 || '%''';\n    END IF;\nEND\n$$;",
        "options": {
          "queryReplacement": "={{ $json.file_id }}"
        }
      },
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.5,
      "position": [
        680,
        620
      ],
      "id": "e464e2b3-1a45-4a68-ab89-1d999d681192",
      "name": "Delete Old Doc Records",
      "credentials": {
        "postgres": {
          "id": "UaTmh0frrACTMPxG",
          "name": "Postgres account"
        }
      }
    },
    {
      "parameters": {
        "triggerOn": "folder",
        "path": "/data/shared",
        "events": [
          "add",
          "change"
        ],
        "options": {
          "followSymlinks": true,
          "usePolling": true
        }
      },
      "type": "n8n-nodes-base.localFileTrigger",
      "typeVersion": 1,
      "position": [
        60,
        620
      ],
      "id": "e8fa3726-a1d8-41c4-954c-a0e78f320c3d",
      "name": "Local File Trigger"
    },
    {
      "parameters": {
        "fileSelector": "={{ $('Set File ID').item.json.file_id }}",
        "options": {
          "dataPropertyName": "=data"
        }
      },
      "type": "n8n-nodes-base.readWriteFile",
      "typeVersion": 1,
      "position": [
        880,
        740
      ],
      "id": "b6425dff-128c-4f1c-88a7-e582789fc069",
      "name": "Read/Write Files from Disk"
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "-- Create a table to store your documents\ncreate table documents_reranking (\n  id bigserial primary key,\n  text text,\n  metadata jsonb,\n  embedding vector(1536) -- 1536 works for OpenAI embeddings, change if needed\n);\n-- Create a function to search for documents\ncreate function match_documents_reranking (\n  query_embedding vector(1536),\n  match_count int default null,\n  filter jsonb DEFAULT '{}'\n) returns table (\n  id bigint,\n  text text,\n  metadata jsonb,\n  similarity float\n)\nlanguage plpgsql\nas $$\n#variable_conflict use_column\nbegin\n  return query\n  select\n    id,\n    text,\n    metadata,\n    1 - (documents_reranking.embedding <=> query_embedding) as similarity\n  from documents_reranking\n  where metadata @> filter\n  order by documents_reranking.embedding <=> query_embedding\n  limit match_count;\nend;\n$$;",
        "options": {}
      },
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.6,
      "position": [
        1180,
        280
      ],
      "id": "ebae020c-c574-4f5b-bdcf-7d24093ff64d",
      "name": "Postgres",
      "credentials": {
        "postgres": {
          "id": "UaTmh0frrACTMPxG",
          "name": "Postgres account"
        }
      }
    },
    {
      "parameters": {
        "content": "## Run Once to Set Up the Database",
        "height": 320,
        "width": 740,
        "color": 3
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        880,
        160
      ],
      "id": "169e189c-8bf8-47f5-b8e1-13fed9af397e",
      "name": "Sticky Note"
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "10646eae-ae46-4327-a4dc-9987c2d76173",
              "name": "file_id",
              "value": "={{ $json.path }}",
              "type": "string"
            },
            {
              "id": "f4536df5-d0b1-4392-bf17-b8137fb31a44",
              "name": "file_type",
              "value": "={{ $json.path.split(/[\\\\/]/).pop().split('.').pop(); }}",
              "type": "string"
            },
            {
              "id": "77d782de-169d-4a46-8a8e-a3831c04d90f",
              "name": "file_title",
              "value": "={{ $json.path.split(/[\\\\/]/).pop().split('.').slice(0, -1).join('.'); }}",
              "type": "string"
            }
          ]
        },
        "options": {}
      },
      "id": "a4647a15-a270-46f8-aa12-b966c55f974a",
      "name": "Set File ID",
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        480,
        760
      ]
    },
    {
      "parameters": {
        "sseEndpoint": "http://host.docker.internal:8050/sse"
      },
      "type": "@n8n/n8n-nodes-langchain.mcpClientTool",
      "typeVersion": 1,
      "position": [
        640,
        300
      ],
      "id": "c8027479-416e-4101-8bba-644f96ef483c",
      "name": "Reranking RAG MCP Server"
    }
  ],
  "pinData": {},
  "connections": {
    "OpenAI Chat Model": {
      "ai_languageModel": [
        [
          {
            "node": "RAG AI Agent",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Extract Document Text": {
      "main": [
        [
          {
            "node": "Create Chunks From Doc",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Embeddings OpenAI1": {
      "ai_embedding": [
        [
          {
            "node": "Postgres PGVector Store",
            "type": "ai_embedding",
            "index": 0
          }
        ]
      ]
    },
    "Default Data Loader": {
      "ai_document": [
        [
          {
            "node": "Postgres PGVector Store",
            "type": "ai_document",
            "index": 0
          }
        ]
      ]
    },
    "Postgres Chat Memory": {
      "ai_memory": [
        [
          {
            "node": "RAG AI Agent",
            "type": "ai_memory",
            "index": 0
          }
        ]
      ]
    },
    "Loop Over Items": {
      "main": [
        [],
        [
          {
            "node": "Set File ID",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Recursive Character Text Splitter": {
      "ai_textSplitter": [
        [
          {
            "node": "Default Data Loader",
            "type": "ai_textSplitter",
            "index": 0
          }
        ]
      ]
    },
    "When chat message received": {
      "main": [
        [
          {
            "node": "RAG AI Agent",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Chunks To List": {
      "main": [
        [
          {
            "node": "Generate Contextual Text",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Create Chunks From Doc": {
      "main": [
        [
          {
            "node": "Chunks To List",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "OpenAI Chat Model3": {
      "ai_languageModel": [
        [
          {
            "node": "Generate Contextual Text",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Generate Contextual Text": {
      "main": [
        [
          {
            "node": "Get Values",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Get Values": {
      "main": [
        [
          {
            "node": "Postgres PGVector Store",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Postgres PGVector Store": {
      "main": [
        [
          {
            "node": "Loop Over Items",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Delete Old Doc Records": {
      "main": [
        [
          {
            "node": "Read/Write Files from Disk",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Local File Trigger": {
      "main": [
        [
          {
            "node": "Loop Over Items",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Read/Write Files from Disk": {
      "main": [
        [
          {
            "node": "Extract Document Text",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Set File ID": {
      "main": [
        [
          {
            "node": "Delete Old Doc Records",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Reranking RAG MCP Server": {
      "ai_tool": [
        [
          {
            "node": "RAG AI Agent",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    }
  },
  "active": true,
  "settings": {
    "executionOrder": "v1"
  },
  "versionId": "0dd640ba-ba13-4394-ad87-cd38930b6f60",
  "meta": {
    "templateCredsSetupCompleted": true,
    "instanceId": "73cb7a3e883df514bb47e8d1b34526d30e2abb8f56cd99f10d5948a1e11b25aa"
  },
  "id": "56UAMdcVowXcTMXE",
  "tags": []
}